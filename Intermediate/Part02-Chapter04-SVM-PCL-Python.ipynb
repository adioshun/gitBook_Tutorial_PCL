{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [features.py](https://github.com/mkhuthir/RoboND-Perception-Project/blob/master/src/sensor_stick/src/sensor_stick/features.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "\n",
    "def rgb_to_hsv(rgb_list):\n",
    "    rgb_normalized = [1.0*rgb_list[0]/255, 1.0*rgb_list[1]/255, 1.0*rgb_list[2]/255]\n",
    "    hsv_normalized = matplotlib.colors.rgb_to_hsv([[rgb_normalized]])[0][0]\n",
    "    return hsv_normalized\n",
    "\n",
    "def compute_color_histograms_PCD(cloud, using_hsv=False):\n",
    "\n",
    "    # Compute histograms for the clusters\n",
    "    point_colors_list = []\n",
    "\n",
    "    \"\"\"\n",
    "    # Step through each point in the point cloud for ROS msg\n",
    "    for point in pc2.read_points(cloud, skip_nans=True): \n",
    "        rgb_list = float_to_rgb(point[3])\n",
    "        if using_hsv:\n",
    "            point_colors_list.append(rgb_to_hsv(rgb_list) * 255)\n",
    "        else:\n",
    "            point_colors_list.append(rgb_list)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step through each point in the point cloud for PCD\n",
    "    for point in cloud[:,3]: # for PCD file\n",
    "        rgb_list = float_to_rgb(point)\n",
    "        if using_hsv:\n",
    "            point_colors_list.append(rgb_to_hsv(rgb_list) * 255)\n",
    "        else:\n",
    "            point_colors_list.append(rgb_list)\n",
    "\n",
    "    # Populate lists with color values\n",
    "    channel_1_vals = []\n",
    "    channel_2_vals = []\n",
    "    channel_3_vals = []\n",
    "\n",
    "    for color in point_colors_list:\n",
    "        channel_1_vals.append(color[0])\n",
    "        channel_2_vals.append(color[1])\n",
    "        channel_3_vals.append(color[2])\n",
    "    \n",
    "    # Compute histograms\n",
    "    nbins=32\n",
    "    bins_range=(0, 256)\n",
    "        \n",
    "    # Compute the histogram of the channels separately\n",
    "    channel_1_hist = np.histogram(channel_1_vals, bins=nbins, range=bins_range)\n",
    "    channel_2_hist = np.histogram(channel_2_vals, bins=nbins, range=bins_range)\n",
    "    channel_3_hist = np.histogram(channel_3_vals, bins=nbins, range=bins_range)\n",
    "    \n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel_1_hist[0], channel_2_hist[0], channel_1_hist[0])).astype(np.float64)\n",
    "    \n",
    "    # Normalize the result\n",
    "    normed_features = hist_features / np.sum(hist_features)\n",
    "\n",
    "    # Generate random features for demo mode.  \n",
    "    # Replace normed_features with your feature vector\n",
    "    #normed_features = np.random.random(96) \n",
    "\n",
    "    # Return the feature vector\n",
    "    return normed_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_normals(cloud_path):\n",
    "    \"\"\"\n",
    "    The actual *compute* call from the NormalEstimation class does nothing internally but:\n",
    "    for each point p in cloud P\n",
    "        1. get the nearest neighbors of p\n",
    "        2. compute the surface normal n of p\n",
    "        3. check if n is consistently oriented towards the viewpoint and flip otherwise\n",
    "\n",
    "    # normals: pcl._pcl.PointCloud_Normal,size: 26475\n",
    "    # cloud: pcl._pcl.PointCloud\n",
    "    \"\"\"\n",
    "    cloud = pcl.load(cloud_path)\n",
    "    \n",
    "    feature = cloud.make_NormalEstimation()\n",
    "    #feature.set_RadiusSearch(0.1) #Use all neighbors in a sphere of radius 3cm\n",
    "    \n",
    "    feature.set_KSearch(3)\n",
    "    normals = feature.compute()\n",
    "    \n",
    "    return normals\n",
    "\n",
    "def compute_normal_histograms(normal_cloud, nbins=32, nrange=(-1,1)):\n",
    "    '''\n",
    "    Computes and bins the point-cloud data using the objects distribution of surface normals.\n",
    "    :param: normal_cloud, point cloud containing the filtered clusters.\n",
    "    :param: nbins,number of bins that data will be pooled into.\n",
    "    :param: nrange, value range of the data to be pooled.\n",
    "    :return: the normalised histogram of surface normals\n",
    "    '''\n",
    "    norm_x_vals = []\n",
    "    norm_y_vals = []\n",
    "    norm_z_vals = []\n",
    "\n",
    "    for I in range(0,normal_cloud.size):\n",
    "        norm_x_vals.append(normal_cloud[I][0])\n",
    "        norm_y_vals.append(normal_cloud[I][1])\n",
    "        norm_z_vals.append(normal_cloud[I][2])\n",
    "\n",
    "    # Compute histograms of normal values (just like with color)\n",
    "    norm_x_hist = np.histogram(norm_x_vals, bins=nbins, range=nrange)\n",
    "    norm_y_hist = np.histogram(norm_y_vals, bins=nbins, range=nrange)\n",
    "    norm_z_hist = np.histogram(norm_z_vals, bins=nbins, range=nrange) \n",
    "\n",
    "    # Concatenate and normalize the histograms\n",
    "    hist_features = np.concatenate((norm_x_hist[0], norm_y_hist[0], norm_z_hist[0])).astype(np.float64)\n",
    "    normed_features = hist_features / np.sum(hist_features)\n",
    "\n",
    "    return normed_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = pcl.load_XYZRGB(\"tabletop.pcd\")\n",
    "sample_cloud = cloud.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Color Histogram for the spawned model\n",
    "# Enable using_hsv for better results\n",
    "c_hists = compute_color_histograms_PCD(sample_cloud, using_hsv=True)\n",
    "\n",
    "# Generate normals and notmal histograms for the spawned model\n",
    "normals = get_normals(\"tabletop.pcd\")\n",
    "n_hists = compute_normal_histograms(normals)\n",
    "\n",
    "# Generate feature by concatenate of color and normals.\n",
    "feature = np.concatenate((c_hists, n_hists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Predicted Result : ', 'soap')\n"
     ]
    }
   ],
   "source": [
    "detected_objects = []\n",
    "# Make the prediction, retrieve the label for the result\n",
    "# and add it to detected_objects_labels list\n",
    "################################\n",
    "model = pickle.load(open('model.sav', 'rb'))\n",
    "#https://raw.githubusercontent.com/mkhuthir/RoboND-Perception-Project/master/model.sav\n",
    "\n",
    "clf = model['classifier']\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = model['classes']\n",
    "scaler = model['scaler']\n",
    "\n",
    "prediction = clf.predict(scaler.transform(feature.reshape(1,-1)))\n",
    "label = encoder.inverse_transform(prediction)[0]\n",
    "print(\"Predicted Result : \", label)\n",
    "#모든 결과를 Soap로 인식, 수정 필요 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
